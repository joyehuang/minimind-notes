<div align="center">

# ğŸ§  MiniMind | LLM Training Principles Tutorial

<p>
  <strong>From 0 to 1: Understanding Large Models - Not a "copy-paste" manual, but a principle-first experimental lab</strong>
  <br>
  <em>From 0 to 1: Not a "copy-paste" manual, but a principle-first experimental lab for LLMs.</em>
</p>

<p>
  <a href="https://minimind.wiki">
    <img src="https://img.shields.io/badge/Documentation-Wiki-blue?style=for-the-badge&logo=read-the-docs" alt="Website">
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License">
  </a>
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
  </a>
</p>

<h3>
  ğŸ‰ Full Interactive Documentation Live
  <br>
  <a href="https://minimind.wiki">ğŸ‘‰ https://minimind.wiki ğŸ‘ˆ</a>
</h3>

<p>
  <a href="#-quick-start">âš¡ Quick Start</a> â€¢ 
  <a href="#-learning-paths">ğŸ—ºï¸ Learning Paths</a> â€¢ 
  <a href="#-module-navigation">ğŸ“¦ Module Navigation</a> â€¢ 
  <a href="README.md">ğŸ‡¨ğŸ‡³ ä¸­æ–‡ README</a>
</p>

</div>

---

## ğŸ“– Introduction

MiniMind aims to help developers deeply understand the training mechanisms of Large Language Models (LLMs) through practice, using extremely concise code and **comparative experiments**. It not only tells you "how to do it" but also shows you "why to do it this way" through experimental data.

> **Why this project?** Understand every design choice in LLM training through comparative experiments.

---

## ğŸ¯ What is This?

This is a **modular LLM training tutorial** that helps you understand the training principles of modern large language models (such as Llama, GPT).

**Core Features**:
- âœ… **Principle-First**: Understand "why it's designed this way", not just "how to run it"
- âœ… **Comparative Experiments**: Each design choice answers "what happens if we don't do this" through experiments
- âœ… **Modular**: 6 independent modules, from basic components to complete architecture
- âœ… **Low Barrier**: Learning-stage experiments can run on CPU (minutes), full training requires GPU

**Based on Project**: [MiniMind](https://github.com/jingyaogong/minimind) - Complete tutorial for training ultra-small language models from scratch

---

## ğŸ‘¥ Who is This For?

### ğŸ¯ **Perfect for Students Seeking LLM Internships/Jobs!**

This project is especially designed for students who want to enter the LLM field. By systematically learning LLM training principles, you will:
- âœ… **Ace Interviews**: Deep understanding of Transformer, Attention, RoPE, and other core mechanisms helps you excel in technical interviews
- âœ… **Stand Out**: Complete comparative experiments to showcase your deep understanding of LLM principles, making your resume more competitive
- âœ… **Quick Start**: Understand modern LLM (Llama, GPT) training pipelines from scratch, not just a "framework user"
- âœ… **Career Growth**: Master LLM training principles to build a solid foundation for future LLM-related work

---

### ğŸ“ Students and Researchers
- **ğŸ¯ Students Seeking LLM Internships/Jobs**: Systematically learn LLM training principles to improve technical interview success rates
- **ğŸ“š ML/DL Students**: Deeply understand the internal mechanisms of Transformers and LLMs, move beyond theory
- **ğŸ”¬ Graduate Students/PhD Candidates**: Understand LLM training principles to provide a solid foundation for research and paper writing
- **ğŸ’¡ Researchers**: Understand design choices in modern LLM architectures and their underlying principles to inspire research directions

### ğŸ’» Developers
- **ğŸ¤– AI/ML Engineers**: Progress from "knowing how to use frameworks" to "understanding principles" to solve real problems with confidence
- **ğŸŒ Full-Stack Developers**: Interested in LLMs and want to systematically learn training mechanisms to expand your tech stack
- **âš™ï¸ Algorithm Engineers**: Need to optimize or improve LLM training pipelines, understanding principles is key to making the right decisions

### ğŸš€ Learners
- **ğŸ“– With PyTorch Basics**: Familiar with basic deep learning concepts, want to dive deep into LLMs
- **ğŸ› ï¸ Hands-on Learners**: Prefer understanding through experiments and code, not just theory
- **ğŸ” Seek Deep Understanding**: Not satisfied with "getting code to work", want to know "why it's designed this way"

### âŒ Not For
- Complete beginners (suggest learning PyTorch basics first)
- Users who only want to quickly deploy models without understanding principles
- Users needing production-ready code and best practices (this project focuses on teaching)

**ğŸ’ª If you're preparing for LLM job interviews or want to deeply understand LLM training principles, this project is for you!** ğŸš€

---

## âš¡ Quick Start

### 30-Minute Experience of Core Design

Run three key experiments to understand the core design choices of LLMs:

```bash
# 1. Clone the repository
git clone https://github.com/joyehuang/minimind-notes.git
cd minimind-notes

# 2. Activate virtual environment (if you have one)
source venv/bin/activate

# 3. Experiment 1: Why do we need normalization?
cd modules/01-foundation/01-normalization/experiments
python exp1_gradient_vanishing.py

# 4. Experiment 2: Why use RoPE positional encoding?
cd ../../02-position-encoding/experiments
python exp1_rope_basics.py

# 5. Experiment 3: How does Attention work?
cd ../../03-attention/experiments
python exp1_attention_basics.py
```

**What You'll See**:
- Visualization of gradient vanishing
- Principles of RoPE rotational encoding
- Calculation process of Attention weights

**Next Step**: Read [ROADMAP.md](./ROADMAP.md) to choose your learning path

---

## ğŸ“š Learning Paths

Choose the appropriate path based on your time and goals:

| Path | Duration | Goal | Link |
|------|----------|------|------|
| âš¡ **Quick Experience** | 30 minutes | Understand core design choices | [Start](./ROADMAP.md#-quick-experience-30-minutes) |
| ğŸ“š **Systematic Learning** | 6 hours | Master basic components | [Start](./ROADMAP.md#-systematic-learning-6-hours) |
| ğŸ“ **Deep Mastery** | 30+ hours | Train model from scratch | [Start](./ROADMAP.md#-deep-mastery-30-hours) |

Detailed roadmap: [ROADMAP.md](./ROADMAP.md)

---

## ğŸ§± Module Navigation

### Tier 1: Foundation (Basic Components)

| Module | Core Question | Experiments | Status |
|--------|---------------|-------------|--------|
| [01-normalization](modules/01-foundation/01-normalization) | Why normalization? Pre-LN vs Post-LN? | 2 | âœ… Complete |
| [02-position-encoding](modules/01-foundation/02-position-encoding) | Why choose RoPE? How to extrapolate length? | 4 | ğŸŸ¡ Experiments Complete |
| [03-attention](modules/01-foundation/03-attention) | What's the intuition behind QKV? Why multi-head? | 3 | ğŸŸ¡ Experiments Complete |
| [04-feedforward](modules/01-foundation/04-feedforward) | What knowledge does FFN store? Why expansion? | 1 | ğŸŸ¡ Experiments Complete |

### Tier 2: Architecture (Architecture Assembly)

| Module | Core Question | Status |
|--------|---------------|--------|
| [01-residual-connection](modules/02-architecture/01-residual-connection) | Why residual connections? How to stabilize gradients? | ğŸ”œ To Be Developed |
| [02-transformer-block](modules/02-architecture/02-transformer-block) | How to assemble components? Why this order? | ğŸ”œ To Be Developed |

**Legend**:
- âœ… Complete: Includes teaching docs + experiment code + quizzes
- ğŸŸ¡ Experiments Complete: Has experiment code, docs to be added
- ğŸ”œ To Be Developed: Directory structure only

Detailed navigation: [modules/README.md](modules/README.md)

---

## ğŸ”¬ Experimental Features

### 1. Comparative Experiment Design

Each module answers core questions through experiments:

**Example**: Normalization Module

| Configuration | Converges? | NaN Appears at Step | Final Loss |
|---------------|------------|-------------------|------------|
| âŒ NoNorm | No | ~500 | NaN |
| âš ï¸ Post-LN | Yes | - | 3.5 |
| âœ… Pre-LN + RMSNorm | Yes | - | 2.7 |

**Conclusion**: Pre-LN + RMSNorm is most stable â†’ Standard choice for modern LLMs

---

### 2. Progressive Learning

```
Experiment â†’ Intuition â†’ Theory â†’ Code
  â†“         â†“         â†“        â†“
10 min    20 min    30 min   10 min
```

Run experiments first to build intuition, then study theory to understand principles, finally read source code to master implementation.

---

### 3. Runs on Laptops

All experiments are based on **TinyShakespeare** (1MB) or synthetic data:
- âœ… No GPU required (CPU/MPS both work)
- âœ… Each experiment < 10 minutes
- âœ… Total data < 100 MB

---

## ğŸ“– Document Structure

Each module contains:

```
01-normalization/
â”œâ”€â”€ README.md           # Module navigation
â”œâ”€â”€ teaching.md         # Teaching docs (Why/What/How)
â”œâ”€â”€ code_guide.md       # Source code guide (links to MiniMind)
â”œâ”€â”€ quiz.md            # Self-assessment questions
â””â”€â”€ experiments/        # Comparative experiments
    â”œâ”€â”€ exp1_*.py
    â”œâ”€â”€ exp2_*.py
    â””â”€â”€ results/        # Expected outputs
```

**Document Template** (teaching.md):
1. **Why**: Problem scenario + intuitive understanding
2. **What**: Mathematical definition + comparison table
3. **How**: Experimental design + expected results

---

## ğŸ› ï¸ Tech Stack

- **Framework**: PyTorch 2.0+
- **Data**: TinyShakespeare, TinyStories
- **Visualization**: Matplotlib, Seaborn
- **Original Project**: [MiniMind](https://github.com/jingyaogong/minimind)

---

## ğŸ¤ Contributing

Welcome contributions:
- âœ¨ New comparative experiments
- ğŸ“Š Better visualizations
- ğŸŒ English translations
- ğŸ› Bug fixes

**Before submitting, please ensure**:
- [ ] Experiments can run independently
- [ ] Code has sufficient comments
- [ ] Results are reproducible (fixed random seed)
- [ ] Follows existing file structure

---

## ğŸ“‚ Repository Structure

```
minimind-notes/
â”œâ”€â”€ modules/                    # Modular teaching (new architecture)
â”‚   â”œâ”€â”€ common/                # Common utilities
â”‚   â”œâ”€â”€ 01-foundation/         # Basic components
â”‚   â””â”€â”€ 02-architecture/       # Architecture assembly
â”‚
â”œâ”€â”€ docs/                       # Personal learning records
â”‚   â”œâ”€â”€ learning_log.md        # Learning log
â”‚   â”œâ”€â”€ knowledge_base.md      # Knowledge base
â”‚   â””â”€â”€ notes.md              # Index
â”‚
â”œâ”€â”€ model/                      # MiniMind original code
â”œâ”€â”€ trainer/                    # Training scripts
â”œâ”€â”€ dataset/                    # Datasets
â”‚
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ ROADMAP.md                  # Learning roadmap
â””â”€â”€ CLAUDE.md                   # AI assistant guide
```

---

## ğŸ“œ Acknowledgments

This repository is based on the following project:
- [MiniMind](https://github.com/jingyaogong/minimind) - Core code and training pipeline
- All modules link to MiniMind's real implementation

Special thanks to [@jingyaogong](https://github.com/jingyaogong) for open-sourcing the MiniMind project!

---

## ğŸ”— Related Resources

### Online Website
- **[minimind.wiki](https://minimind.wiki)** - Access full documentation and interactive content online

### Papers
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer paper
- [RoFormer: RoPE](https://arxiv.org/abs/2104.09864) - Rotary Position Embedding
- [RMSNorm](https://arxiv.org/abs/1910.07467) - Root Mean Square Layer Normalization

### Blogs
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)

### Videos
- [Andrej Karpathy - Let's build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY)

---

## ğŸ“ Contact

- Issue Feedback: [GitHub Issues](https://github.com/joyehuang/minimind-notes/issues)
- Original Project: [MiniMind](https://github.com/jingyaogong/minimind)

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

---

<div align="center">

**â­ If this project helps you, please give it a Star!**

**ğŸŒ Visit Online Website:** [https://minimind.wiki](https://minimind.wiki)

**Ready to start?** [Begin your learning journey](./ROADMAP.md) ğŸš€

</div>
