"""
ðŸŽ“ ä¸ºä»€ä¹ˆéœ€è¦å½’ä¸€åŒ–ï¼Ÿä»Žé›¶ç†è§£
================================

è¿™ä¸ªç¨‹åºç”¨æœ€ç®€å•çš„ä¾‹å­ï¼Œå±•ç¤º"æ²¡æœ‰å½’ä¸€åŒ–"ä¼šå‘ç”Ÿä»€ä¹ˆé—®é¢˜ã€‚
"""

import torch
import torch.nn as nn


# ============================================================
# å®žéªŒ 1: æ²¡æœ‰å½’ä¸€åŒ– - æ•°å€¼ä¼šçˆ†ç‚¸ï¼
# ============================================================
def experiment_without_normalization():
    print("="*70)
    print("ðŸ”´ å®žéªŒ 1: æ²¡æœ‰å½’ä¸€åŒ–çš„ç¥žç»ç½‘ç»œ")
    print("="*70)

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„è¾“å…¥ï¼ˆæ¨¡æ‹Ÿä¸€ä¸ªè¯çš„åµŒå…¥å‘é‡ï¼‰
    x = torch.randn(1, 1, 512)  # [batch=1, seq_len=1, hidden_size=512]

    print(f"\nåˆå§‹è¾“å…¥:")
    print(f"  å‡å€¼: {x.mean().item():.4f}")
    print(f"  æ ‡å‡†å·®: {x.std().item():.4f}")
    print(f"  æ•°å€¼èŒƒå›´: [{x.min().item():.4f}, {x.max().item():.4f}]")

    # æ¨¡æ‹Ÿ 8 å±‚ç½‘ç»œï¼ˆMiniMind çš„å±‚æ•°ï¼‰
    layers = [nn.Linear(512, 512) for _ in range(8)]

    print(f"\né€šè¿‡ 8 å±‚ç½‘ç»œåŽ...")
    for i, layer in enumerate(layers):
        x = layer(x)
        x = torch.relu(x)  # æ¿€æ´»å‡½æ•°

        print(f"\nç¬¬ {i+1} å±‚è¾“å‡º:")
        print(f"  å‡å€¼: {x.mean().item():.4f}")
        print(f"  æ ‡å‡†å·®: {x.std().item():.4f}")
        print(f"  æ•°å€¼èŒƒå›´: [{x.min().item():.4f}, {x.max().item():.4f}]")

        # æ£€æŸ¥æ˜¯å¦å‡ºçŽ°æ•°å€¼é—®é¢˜
        if x.std() > 100:
            print(f"  âš ï¸  æ¢¯åº¦çˆ†ç‚¸ï¼æ ‡å‡†å·® > 100")
        elif x.std() < 0.01:
            print(f"  âš ï¸  æ¢¯åº¦æ¶ˆå¤±ï¼æ ‡å‡†å·® < 0.01")

    print("\n" + "="*70)
    print("è§‚å¯Ÿ: æ•°å€¼å˜åŒ–éžå¸¸å‰§çƒˆï¼Œæ ‡å‡†å·®å¿½å¤§å¿½å°ï¼Œéš¾ä»¥è®­ç»ƒï¼")
    print("="*70)


# ============================================================
# å®žéªŒ 2: ä½¿ç”¨ RMSNorm - æ•°å€¼ç¨³å®šï¼
# ============================================================
class RMSNorm(nn.Module):
    def __init__(self, dim: int, eps: float = 1e-5):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))

    def _norm(self, x):
        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)

    def forward(self, x):
        return self.weight * self._norm(x.float()).type_as(x)


def experiment_with_normalization():
    print("\n\n")
    print("="*70)
    print("ðŸŸ¢ å®žéªŒ 2: ä½¿ç”¨ RMSNorm çš„ç¥žç»ç½‘ç»œ")
    print("="*70)

    # åŒæ ·çš„åˆå§‹è¾“å…¥
    x = torch.randn(1, 1, 512)

    print(f"\nåˆå§‹è¾“å…¥:")
    print(f"  å‡å€¼: {x.mean().item():.4f}")
    print(f"  æ ‡å‡†å·®: {x.std().item():.4f}")
    print(f"  æ•°å€¼èŒƒå›´: [{x.min().item():.4f}, {x.max().item():.4f}]")

    # æ¨¡æ‹Ÿ 8 å±‚ç½‘ç»œ + RMSNorm
    layers = [nn.Linear(512, 512) for _ in range(8)]
    norms = [RMSNorm(512) for _ in range(8)]

    print(f"\né€šè¿‡ 8 å±‚ç½‘ç»œï¼ˆæ¯å±‚åŽéƒ½æœ‰ RMSNormï¼‰...")
    for i, (layer, norm) in enumerate(zip(layers, norms)):
        x = layer(x)
        x = torch.relu(x)
        x = norm(x)  # å…³é”®ï¼šå½’ä¸€åŒ–ï¼

        print(f"\nç¬¬ {i+1} å±‚è¾“å‡ºï¼ˆå½’ä¸€åŒ–åŽï¼‰:")
        print(f"  å‡å€¼: {x.mean().item():.4f}")
        print(f"  æ ‡å‡†å·®: {x.std().item():.4f}")
        print(f"  æ•°å€¼èŒƒå›´: [{x.min().item():.4f}, {x.max().item():.4f}]")
        print(f"  âœ… æ•°å€¼ç¨³å®šï¼")

    print("\n" + "="*70)
    print("è§‚å¯Ÿ: æ ‡å‡†å·®å§‹ç»ˆä¿æŒåœ¨ 1.0 é™„è¿‘ï¼Œè®­ç»ƒç¨³å®šï¼")
    print("="*70)


# ============================================================
# å®žéªŒ 3: ç›´è§‚å¯¹æ¯”
# ============================================================
def side_by_side_comparison():
    print("\n\n")
    print("="*70)
    print("ðŸ“Š å¯¹æ¯”æ€»ç»“")
    print("="*70)

    print("\nâŒ æ²¡æœ‰å½’ä¸€åŒ–:")
    print("  - æ•°å€¼ä¸å¯æŽ§ï¼Œå¯èƒ½çˆ†ç‚¸æˆ–æ¶ˆå¤±")
    print("  - è®­ç»ƒä¸ç¨³å®šï¼Œæ¢¯åº¦éš¾ä»¥æ›´æ–°")
    print("  - æ¨¡åž‹å¾ˆéš¾æ”¶æ•›")

    print("\nâœ… ä½¿ç”¨ RMSNorm:")
    print("  - æ•°å€¼å§‹ç»ˆä¿æŒåœ¨åˆç†èŒƒå›´")
    print("  - è®­ç»ƒç¨³å®šï¼Œæ¢¯åº¦é¡ºç•…")
    print("  - æ¨¡åž‹å®¹æ˜“æ”¶æ•›")

    print("\n" + "="*70)
    print("ðŸŽ¯ æ€»ç»“: RMSNorm çš„ä½œç”¨")
    print("="*70)
    print("""
RMSNorm çš„æ ¸å¿ƒä½œç”¨ï¼šç¡®ä¿æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¿æŒåœ¨"æ ‡å‡†è§„æ¨¡"

ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼Ÿ
1. è®­ç»ƒç¨³å®šæ€§ï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
2. å­¦ä¹ é€Ÿåº¦ï¼šæ¯ä¸€å±‚éƒ½èƒ½é«˜æ•ˆå­¦ä¹ 
3. æ¨¡åž‹æ€§èƒ½ï¼šæ›´å®¹æ˜“è®­ç»ƒå‡ºå¥½çš„æ¨¡åž‹

ç±»æ¯”ï¼š
- å°±åƒç»™æ°´é¾™å¤´è£…ä¸€ä¸ª"æ°´åŽ‹ç¨³å®šå™¨"
- æ— è®ºè¾“å…¥æ°´åŽ‹å¤šå¤§æˆ–å¤šå°
- è¾“å‡ºçš„æ°´åŽ‹æ€»æ˜¯ç¨³å®šçš„ã€èˆ’é€‚çš„
    """)


# ============================================================
# è¿è¡Œæ‰€æœ‰å®žéªŒ
# ============================================================
if __name__ == "__main__":
    print("\n" + "ðŸŽ“ ä»Žé›¶ç†è§£å½’ä¸€åŒ–çš„å¿…è¦æ€§" + "\n")

    # å®žéªŒ 1: å±•ç¤ºæ²¡æœ‰å½’ä¸€åŒ–çš„é—®é¢˜
    experiment_without_normalization()

    # å®žéªŒ 2: å±•ç¤º RMSNorm çš„æ•ˆæžœ
    experiment_with_normalization()

    # å®žéªŒ 3: æ€»ç»“å¯¹æ¯”
    side_by_side_comparison()

    print("\n\n" + "="*70)
    print("ðŸ’­ æ€è€ƒé¢˜:")
    print("="*70)
    print("""
1. å¦‚æžœåŽ»æŽ‰ RMSNormï¼Œä½ çš„æ¨¡åž‹è¿˜èƒ½è®­ç»ƒå—ï¼Ÿ
   ç­”ï¼šå¯èƒ½å¯ä»¥ï¼Œä½†ä¼šéžå¸¸å›°éš¾ï¼Œéœ€è¦ç²¾å¿ƒè°ƒæ•´å­¦ä¹ çŽ‡

2. RMSNorm æ”¾åœ¨å“ªé‡Œï¼Ÿ
   ç­”ï¼šåœ¨ MiniMind ä¸­ï¼Œæ¯ä¸ª Transformer Block é‡Œæœ‰ 2 ä¸ª RMSNormï¼š
      - ä¸€ä¸ªåœ¨ Attention ä¹‹å‰
      - ä¸€ä¸ªåœ¨ FeedForward ä¹‹å‰

3. ä¸ºä»€ä¹ˆä¸ç›´æŽ¥æŠŠæ‰€æœ‰æƒé‡åˆå§‹åŒ–å¾—å¾ˆå°ï¼Ÿ
   ç­”ï¼šé‚£ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ï¼Œæ¨¡åž‹å­¦ä¸åˆ°ä¸œè¥¿ï¼
      RMSNorm è®©æ¨¡åž‹å¯ä»¥ä½¿ç”¨æ­£å¸¸çš„æƒé‡åˆå§‹åŒ–ã€‚
    """)
