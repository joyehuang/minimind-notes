# Position Encoding ä»£ç å¯¼è¯»

> ç†è§£ MiniMind ä¸­ RoPE çš„çœŸå®å®ç°

---

## ğŸ“‚ ä»£ç ä½ç½®

### 1. é¢„è®¡ç®—æ—‹è½¬é¢‘ç‡

**æ–‡ä»¶**ï¼š`model/model_minimind.py`
**è¡Œæ•°**ï¼š108-128

```python
def precompute_freqs_cis(dim: int, end: int, rope_base: float = 1e6, rope_scaling=None):
    """é¢„è®¡ç®— RoPE çš„æ—‹è½¬é¢‘ç‡"""

    # è®¡ç®—é¢‘ç‡ï¼š1 / (base^(2i/dim))
    freqs = 1.0 / (rope_base ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))

    # ç”Ÿæˆä½ç½®åºåˆ— [0, 1, 2, ..., end-1]
    t = torch.arange(end, device=freqs.device, dtype=torch.float32)

    # YaRN é•¿åº¦å¤–æ¨ï¼ˆå¯é€‰ï¼‰
    if rope_scaling is not None:
        t = t / rope_scaling

    # è®¡ç®—æ¯ä¸ªä½ç½®çš„æ—‹è½¬è§’åº¦ï¼šä½ç½® * é¢‘ç‡
    freqs = torch.outer(t, freqs)  # [end, dim//2]

    # è½¬æ¢ä¸ºå¤æ•°å½¢å¼ï¼ˆcos + i*sinï¼‰
    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # [end, dim//2]

    return freqs_cis
```

---

### 2. åº”ç”¨æ—‹è½¬ç¼–ç 

**æ–‡ä»¶**ï¼š`model/model_minimind.py`
**è¡Œæ•°**ï¼š131-145

```python
def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):
    """å°† RoPE åº”ç”¨åˆ° Query å’Œ Key"""

    # å°†å®æ•°å‘é‡è½¬ä¸ºå¤æ•°
    # [batch, seq, heads, head_dim] -> [batch, seq, heads, head_dim//2, 2]
    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))
    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))

    # è°ƒæ•´ freqs_cis å½¢çŠ¶ä»¥ä¾¿å¹¿æ’­
    freqs_cis = freqs_cis[:, None, :]  # [seq, 1, head_dim//2]

    # å¤æ•°ä¹˜æ³• = æ—‹è½¬
    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)
    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)

    return xq_out.type_as(xq), xk_out.type_as(xk)
```

---

### 3. åœ¨ Attention ä¸­ä½¿ç”¨

**æ–‡ä»¶**ï¼š`model/model_minimind.py`
**è¡Œæ•°**ï¼š250-290

```python
class Attention(nn.Module):
    def forward(self, x, pos_ids, mask):
        batch, seq_len, _ = x.shape

        # è®¡ç®— Q, K, V
        xq = self.wq(x)
        xk = self.wk(x)
        xv = self.wv(x)

        # é‡å¡‘ä¸ºå¤šå¤´å½¢å¼
        xq = xq.view(batch, seq_len, self.n_heads, self.head_dim)
        xk = xk.view(batch, seq_len, self.n_kv_heads, self.head_dim)
        xv = xv.view(batch, seq_len, self.n_kv_heads, self.head_dim)

        # â­ åº”ç”¨ RoPEï¼ˆåªå¯¹ Q å’Œ Kï¼‰
        xq, xk = apply_rotary_emb(xq, xk, self.freqs_cis[pos_ids])

        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        scores = torch.matmul(xq, xk.transpose(-2, -1)) / math.sqrt(self.head_dim)

        # ... åç»­ softmax å’Œè¾“å‡º
```

---

## ğŸ” é€æ­¥è§£æ

### é¢‘ç‡è®¡ç®—å…¬å¼

```python
freqs = 1.0 / (rope_base ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))
```

**åˆ†è§£**ï¼š
1. `torch.arange(0, dim, 2)`ï¼šç”Ÿæˆ [0, 2, 4, ..., dim-2]
2. `[: (dim // 2)]`ï¼šå–å‰ dim/2 ä¸ªï¼ˆå› ä¸ºä¸¤ä¸¤é…å¯¹ï¼‰
3. `/ dim`ï¼šå½’ä¸€åŒ–åˆ° [0, 1)
4. `rope_base ** (...)`ï¼šæŒ‡æ•°è¿ç®—
5. `1.0 / ...`ï¼šå–å€’æ•°å¾—åˆ°é¢‘ç‡

**MiniMind å‚æ•°**ï¼ˆhead_dim=64, rope_base=1e6ï¼‰ï¼š
```
freqs[0]  = 1.0           # é«˜é¢‘ï¼šæ¯ 2Ï€ ä¸ªä½ç½®è½¬ä¸€åœˆ
freqs[15] = 0.001         # ä¸­é¢‘ï¼šæ¯ 6283 ä¸ªä½ç½®è½¬ä¸€åœˆ
freqs[31] = 0.000001      # ä½é¢‘ï¼šæ¯ 628ä¸‡ ä¸ªä½ç½®è½¬ä¸€åœˆ
```

---

### ä¸ºä»€ä¹ˆç”¨å¤æ•°ï¼Ÿ

```python
# å®æ•°å‘é‡ â†’ å¤æ•°
xq_ = torch.view_as_complex(xq.reshape(*xq.shape[:-1], -1, 2))

# å¤æ•°ä¹˜æ³• = æ—‹è½¬
xq_out = xq_ * freqs_cis
```

**åŸå› **ï¼šå¤æ•°ä¹˜æ³•å¤©ç„¶è¡¨ç¤º 2D æ—‹è½¬

$$e^{i\theta} = \cos\theta + i\sin\theta$$

$$(a + bi) \times e^{i\theta} = (a\cos\theta - b\sin\theta) + i(a\sin\theta + b\cos\theta)$$

è¿™æ­£æ˜¯æ—‹è½¬çŸ©é˜µçš„æ•ˆæœï¼

**ç­‰ä»·çš„çŸ©é˜µå½¢å¼**ï¼š
```python
# è¿™ä¸¤ç§å†™æ³•ç­‰ä»·ï¼š
# 1. å¤æ•°ä¹˜æ³•
result = (a + bi) * (cos_Î¸ + i*sin_Î¸)

# 2. çŸ©é˜µä¹˜æ³•
result = [[cos_Î¸, -sin_Î¸],   @  [[a],
          [sin_Î¸,  cos_Î¸]]      [b]]
```

å¤æ•°å½¢å¼æ›´ç®€æ´ã€æ›´å¿«ã€‚

---

### ä¸¤ä¸¤é…å¯¹çš„åŸç†

```python
xq_ = xq.reshape(*xq.shape[:-1], -1, 2)
# [batch, seq, heads, head_dim] â†’ [batch, seq, heads, head_dim//2, 2]
```

**ä¸ºä»€ä¹ˆè¦é…å¯¹ï¼Ÿ**
- 2D æ—‹è½¬éœ€è¦ä¸¤ä¸ªåæ ‡
- æ¯ä¸¤ä¸ªç»´åº¦ç»„æˆä¸€å¯¹ï¼Œåº”ç”¨åŒä¸€ä¸ªæ—‹è½¬è§’åº¦
- head_dim=64 â†’ 32 å¯¹ â†’ 32 ä¸ªä¸åŒé¢‘ç‡

**ç¤ºæ„å›¾**ï¼š
```
head_dim = 64 ç»´

[x0, x1,  x2, x3,  ..., x62, x63]
  â†“   â†“    â†“   â†“         â†“    â†“
 pair0   pair1   ...   pair31

æ¯å¯¹åº”ç”¨ä¸åŒé¢‘ç‡çš„æ—‹è½¬
```

---

## ğŸ’¡ å®ç°æŠ€å·§

### 1. é¢„è®¡ç®— freqs_cis

```python
# åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶é¢„è®¡ç®—
self.freqs_cis = precompute_freqs_cis(
    dim=self.head_dim,
    end=self.max_seq_len,
    rope_base=config.rope_theta
)
```

**ä¼˜ç‚¹**ï¼š
- é¿å…æ¯æ¬¡ forward é‡å¤è®¡ç®—
- æ”¯æŒä»»æ„ä½ç½®ç´¢å¼•ï¼ˆpos_idsï¼‰

---

### 2. ä½¿ç”¨ torch.polar

```python
freqs_cis = torch.polar(torch.ones_like(freqs), freqs)
```

**ç­‰ä»·äº**ï¼š
```python
freqs_cis = torch.exp(1j * freqs)
# æˆ–
freqs_cis = torch.cos(freqs) + 1j * torch.sin(freqs)
```

`torch.polar(r, Î¸)` ç›´æ¥ä»æåæ ‡åˆ›å»ºå¤æ•°ï¼Œæ›´é«˜æ•ˆã€‚

---

### 3. åªå¯¹ Q å’Œ K åº”ç”¨

```python
xq, xk = apply_rotary_emb(xq, xk, freqs_cis)
# V ä¸éœ€è¦ä½ç½®ç¼–ç ï¼
```

**ä¸ºä»€ä¹ˆ V ä¸éœ€è¦ï¼Ÿ**
- Q å’Œ K ç”¨äºè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼ˆéœ€è¦ä½ç½®ä¿¡æ¯ï¼‰
- V æ˜¯"è¢«æŸ¥è¯¢çš„å†…å®¹"ï¼ˆä¸éœ€è¦ä½ç½®ä¿¡æ¯ï¼‰
- ä½ç½®ä¿¡æ¯å·²ç»é€šè¿‡ QÂ·K çš„ç‚¹ç§¯èå…¥äº†

---

### 4. ä¿æŒæ•°æ®ç±»å‹

```python
return xq_out.type_as(xq), xk_out.type_as(xk)
```

**ä¸ºä»€ä¹ˆï¼Ÿ**
- å¤æ•°è¿ç®—éœ€è¦ float32
- ä½†æ¨¡å‹å¯èƒ½ç”¨ BF16/FP16
- è½¬å›åŸå§‹ç±»å‹ä¿æŒä¸€è‡´

---

## ğŸ“Š æ€§èƒ½è€ƒè™‘

### å†…å­˜æ•ˆç‡

```python
# å¥½ï¼šé¢„è®¡ç®—å¹¶å­˜å‚¨
self.register_buffer('freqs_cis', precompute_freqs_cis(...))

# å·®ï¼šæ¯æ¬¡ forward è®¡ç®—
freqs_cis = precompute_freqs_cis(...)  # æµªè´¹è®¡ç®—
```

### è®¡ç®—æ•ˆç‡

å¤æ•°ä¹˜æ³•æ¯”çŸ©é˜µä¹˜æ³•å¿«ï¼š
- çŸ©é˜µï¼š4 æ¬¡ä¹˜æ³• + 2 æ¬¡åŠ æ³•
- å¤æ•°ï¼š2 æ¬¡ä¹˜æ³• + 2 æ¬¡åŠ æ³•ï¼ˆåˆ©ç”¨ GPU ä¼˜åŒ–ï¼‰

---

## ğŸ”¬ å®éªŒéªŒè¯

### éªŒè¯ç›¸å¯¹ä½ç½®æ€§è´¨

```python
# ä½ç½® 5 å’Œ 8
q5 = apply_rotary_emb(q, freqs_cis[5])
k8 = apply_rotary_emb(k, freqs_cis[8])
score_5_8 = q5 @ k8.T

# ä½ç½® 100 å’Œ 103ï¼ˆç›¸å¯¹è·ç¦»ä¹Ÿæ˜¯ 3ï¼‰
q100 = apply_rotary_emb(q, freqs_cis[100])
k103 = apply_rotary_emb(k, freqs_cis[103])
score_100_103 = q100 @ k103.T

# ä¸¤ä¸ªåˆ†æ•°åº”è¯¥ç›¸ç­‰ï¼ˆåªä¾èµ–ç›¸å¯¹è·ç¦»ï¼‰
assert torch.allclose(score_5_8, score_100_103)
```

---

## ğŸ”— ç›¸å…³ä»£ç ä½ç½®

1. **é…ç½®å‚æ•°**ï¼š`model/model_minimind.py:30-65`
   - `rope_theta`ï¼šåŸºç¡€é¢‘ç‡ï¼ˆé»˜è®¤ 1e6ï¼‰
   - `max_position_embeddings`ï¼šæœ€å¤§åºåˆ—é•¿åº¦

2. **YaRN æ”¯æŒ**ï¼š`model/model_minimind.py:120-125`
   - `inference_rope_scaling`ï¼šé•¿åº¦å¤–æ¨ç³»æ•°

3. **å®Œæ•´ Attention**ï¼š`model/model_minimind.py:250-330`
   - åŒ…å« GQAï¼ˆGrouped Query Attentionï¼‰

---

## ğŸ¯ åŠ¨æ‰‹ç»ƒä¹ 

### ç»ƒä¹  1ï¼šå¯è§†åŒ–æ—‹è½¬

ä¿®æ”¹ `exp2_multi_frequency.py`ï¼Œç»˜åˆ¶ä¸åŒé¢‘ç‡çš„æ—‹è½¬æ›²çº¿ï¼š
```python
import matplotlib.pyplot as plt

freqs = precompute_freqs_cis(dim=64, end=100)
for i in [0, 15, 31]:
    plt.plot(freqs[:, i].real, label=f'freq_{i}')
plt.legend()
plt.show()
```

### ç»ƒä¹  2ï¼šéªŒè¯ç›¸å¯¹ä½ç½®

ç¼–å†™ä»£ç éªŒè¯ï¼šä½ç½® (5, 8) å’Œ (100, 103) çš„æ³¨æ„åŠ›åˆ†æ•°ç›¸ç­‰ã€‚

### ç»ƒä¹  3ï¼šå¯¹æ¯”ç»å¯¹ä½ç½®ç¼–ç 

å®ç°ä¸€ä¸ªç®€å•çš„ç»å¯¹ä½ç½®ç¼–ç ï¼Œå¯¹æ¯” RoPE çš„é•¿åº¦å¤–æ¨èƒ½åŠ›ã€‚

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

- MiniMind å®Œæ•´ä»£ç ï¼š`model/model_minimind.py`
- Llama 2 æºç ï¼š[facebookresearch/llama](https://github.com/facebookresearch/llama)
- RoFormer è®ºæ–‡ï¼š[arXiv:2104.09864](https://arxiv.org/abs/2104.09864)
